### model
model_name_or_path: meta-llama/Meta-Llama-3-8B-Instruct  # 1. 模型

### method
stage: sft
do_train: true
finetuning_type: lora
lora_target: all  # 2. 这里全上
lora_rank: 16  # 3. 默认是 8 

### dataset
dataset: identity,alpaca_en_demo  # 4. 数据集
 # 5. 模版 
template: llama3 
# template: chatglm3  # chatglm3
# template: qwen  # qwen1.5 qwen2
# template: glm4  # glm-4

cutoff_len: 1024
max_samples: 1000  # 是否测试 min(max_samples, len(dataset))
overwrite_cache: true
preprocessing_num_workers: 16

### output
output_dir: saves/llama3-8b/lora/sft  # 6. 存储路径
logging_steps: 10
save_strategy: epoch  # 7. 每个epoch结束后存储
save_steps: 500
plot_loss: true
overwrite_output_dir: true

### train
per_device_train_batch_size: 1  # 8.单卡batch-size； v100 2都会爆； 
gradient_accumulation_steps: 8
learning_rate: 1.0e-4
num_train_epochs: 3.0  # 9. epochs
lr_scheduler_type: cosine
warmup_ratio: 0.1
fp16: true
ddp_timeout: 180000000

### eval
val_size: 0.1  # 10. val size
per_device_eval_batch_size: 1  # 11. val batch
eval_strategy: epoch  # 12. 每个epoch结束后eval
eval_steps: 500  # 13. eval-stratyge  设置为 epoch 的时候就无效了
